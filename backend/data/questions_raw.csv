Pertanyaan
Kamu diberi dataset penjualan dengan 20% data hilang. Bagaimana kamu menentukan apakah missing value perlu diimputasi atau dibuang?
Jika grafik penjualan tiba-tiba menurun pada satu minggu tertentu, teknik EDA apa yang pertama kamu lakukan?
Kamu menemukan outlier ekstrem pada data keuangan. Bagaimana kamu mengecek apakah itu error atau kejadian valid?
Jika stakeholder meminta insight cepat, tetapi datamu belum bersih, strategi apa yang kamu lakukan?
Bagaimana kamu menentukan jenis grafik terbaik untuk menjelaskan tren musiman kepada manajemen?
Jika hasil SQL dan dashboard BI berbeda, langkah apa yang kamu tempuh untuk menemukan sumber masalah?
Bagaimana kamu menggunakan analisis korelasi untuk menemukan faktor-faktor yang mempengaruhi retensi pelanggan?
Dataset yang kamu terima memiliki 100 kolom. Bagaimana kamu memilih kolom mana yang paling relevan untuk analisis?
Bagaimana kamu menjelaskan hasil analisis statistik kepada stakeholder non-teknis?
Jika tolok ukur performa perusahaan berubah, bagaimana kamu memperbarui KPI dalam dashboard?
Kamu menemukan distribusi data sangat skewed. Teknik transformasi apa yang kamu pilih?
Bagaimana kamu menilai apakah sebuah variabel merupakan confounding variable?
Jika hasil A/B testing tidak signifikan secara statistik, apakah eksperimen harus dihentikan atau diperbaiki?
Bagaimana kamu menilai kualitas data dari berbagai sumber sebelum dianalisis?
Jika dataset sangat besar, bagaimana kamu melakukan EDA tanpa loading penuh ke RAM?
Bagaimana kamu menganalisis anomali yang muncul di time-series mingguan?
Bagaimana kamu memutuskan apakah harus menggunakan median atau mean sebagai measure of center?
Ketika data memiliki banyak kategori unik, bagaimana kamu menanganinya dalam analisis?
Jika kamu menemukan multikolinearitas dalam analisis regresi, apa langkah koreksi yang kamu lakukan?
Bagaimana kamu menentukan apakah korelasi bersifat kausal atau tidak?
Bagaimana kamu menggunakan pivot table untuk menemukan pola tersembunyi?
Jika histogram menunjukkan pola multimodal, apa interpretasi awalmu?
Bagaimana kamu menentukan metode sampling terbaik ketika dataset terlalu besar?
Jika stakeholders meminta insight dari data real-time, alat BI apa yang kamu gunakan?
Bagaimana kamu melakukan data cleaning pada data yang bersifat semi-terstruktur?
Kamu menemukan duplikasi data pelanggan. Bagaimana menentukan duplikasi yang valid atau tidak?
Jika terjadi perbedaan tipe data antara sumber sistem, bagaimana kamu menyeragamkannya?
Bagaimana kamu menentukan confidence interval yang tepat untuk laporan analisis?
Jika kamu menemukan hubungan nonlinear, apakah korelasi Pearson masih tepat digunakan?
Bagaimana kamu mengidentifikasi faktor penyebab churn pelanggan?
Jika kamu harus membuat dashboard dalam sehari, bagian mana yang kamu prioritaskan?
Bagaimana kamu mengevaluasi efektivitas promosi menggunakan data transaksi?
Bagaimana kamu membuat segmentasi pelanggan hanya dengan data demografis?
Jika kamu menemukan nilai negatif pada kolom yang tidak boleh negatif, apa langkah investigasimu?
Bagaimana kamu menentukan granularity yang tepat untuk analisis time-series?
Jika meeting butuh insight cepat, bagaimana kamu melakukan EDA super singkat?
Bagaimana kamu mendeteksi apakah data bersifat seasonality atau tidak?
Bagaimana kamu mengukur dampak suatu kebijakan perusahaan menggunakan data historis?
Jika data tidak normal, apakah uji-t masih dapat digunakan?
Bagaimana kamu menentukan apakah data memiliki heteroskedastisitas?
Jika kamu harus menggabungkan dua dataset berbeda struktur, apa strategi terbaik?
Bagaimana kamu menghindari misinterpretasi saat memvisualisasikan data?
Jika p-value rendah tetapi efek tidak praktis, bagaimana kamu menjelaskannya?
Bagaimana kamu mendeteksi data drift dalam dataset historis?
Jika dashboard lambat, optimasi apa yang kamu lakukan?
Kamu perlu memberi insight yang actionable. Apa tiga langkah inti yang kamu lakukan?
Bagaimana kamu memilih antara heatmap atau correlation matrix?
Jika hanya punya 5 menit untuk presentasi data, apa yang kamu tampilkan?
Bagaimana kamu menangani kategori imbalance dalam analisis?
Dataset hanya memiliki 50 baris, teknik analisis apa yang aman digunakan?
Bagaimana kamu menentukan apakah dataset cukup representatif?
Jika kamu diberi pertanyaan bisnis tanpa data, bagaimana kamu menentukan data yang diperlukan?
Bagaimana kamu menilai apakah sebuah fitur benar-benar mempengaruhi outcome?
Bagaimana kamu melakukan root-cause analysis berbasis data?
Jika key metric perusahaan stagnan, analisis apa yang pertama kamu lakukan?
Bagaimana kamu mendeteksi trend reversal pada data penjualan?
Jika kamu tidak boleh menghapus outlier, apa strategi alternatif?
Bagaimana kamu memvalidasi hasil analisis agar tidak bias?
Jika hasil analisis bertentangan dengan intuisi manajemen, apa yang kamu lakukan?
Bagaimana kamu menentukan ukuran sample minimal untuk eksperimen?
Jika kategori terlalu banyak, bagaimana kamu menyederhanakannya?
Bagaimana kamu menentukan KPI utama dari dataset yang kompleks?
Jika kamu menemukan missing value pada kolom target, apa langkah selanjutnya?
Bagaimana kamu membuat wawasan dari dataset yang sangat noise?
Jika ada perubahan besar mendadak di dataset, bagaimana kamu mengonfirmasi penyebabnya?
Bagaimana kamu memutuskan apakah perlu membuat fitur baru untuk analisis?
Jika kamu menyadari laporan salah karena script, bagaimana kamu memperbaikinya?
Bagaimana kamu memilih chart terbaik untuk menunjukkan distribusi kategorikal?
Jika stakeholders meminta filter tambahan, bagaimana kamu memperbaiki dashboard?
Bagaimana kamu memprioritaskan tugas analisis saat semuanya terasa penting?
Dataset berisi teks panjang. Analisis apa yang relevan?
Jika variabel numerik memiliki banyak nilai nol, bagaimana kamu memperlakukannya?
Bagaimana kamu mengecek apakah data mengalami seasonality mingguan?
Jika dataset hasil merge membengkak dua kali lipat, apa yang kamu periksa?
Bagaimana kamu membuat laporan analisis yang mudah dipahami?
Jika perusahaan meminta prediksi tanpa model ML, metode apa yang kamu pilih?
Bagaimana kamu membuktikan bahwa insight benar-benar berdampak bisnis?
Bagaimana kamu menentukan depth insight yang tepat untuk eksekutif?
Jika value berubah karena timezone, bagaimana kamu menanganinya?
Bagaimana kamu mengevaluasi performa dashboard BI?
Jika data terlalu granular, bagaimana kamu menaikkan level agregasi?
Bagaimana kamu menentukan apakah data perlu distandarisasi sebelum analisis?
Jika kamu harus membangun automated report, pipeline apa yang kamu pilih?
Bagaimana kamu mencegah misinterpretasi angka oleh stakeholder?
Jika dataset mengandung banyak kolom boolean, analisis apa yang paling relevan?
Bagaimana kamu memilih metode forecasting yang paling masuk akal?
Bagaimana kamu memastikan integritas data saat update harian?
Jika data tidak update, langkah troubleshooting apa yang kamu lakukan?
Bagaimana kamu melakukan sanity check sebelum menganalisis dataset besar?
Jika grafik menunjukkan fluktuasi tinggi, apa hipotesis awalmu?
Bagaimana kamu menentukan threshold anomaly detection sederhana?
Jika kamu harus memutuskan insight mana yang ditampilkan, apa kriteriamu?
Bagaimana kamu merancang dashboard agar membantu pengambilan keputusan harian?
Jika kamu harus memilih antara data lengkap dan data terbaru, mana yang kamu prioritaskan?
Bagaimana kamu melakukan benchmarking antar cabang perusahaan menggunakan data?
Jika dataset memiliki variasi tinggi antar grup, bagaimana kamu menghitung perbandingan secara adil?
Bagaimana kamu mengidentifikasi metrik palsu yang terlihat bagus tetapi tidak bermakna?
Jika data sangat tidak stabil, bagaimana kamu mengkomunikasikan ketidakpastian ke manajemen?
Sebuah pipeline ETL harian tiba-tiba memproses data dua kali lipat dari biasanya. Langkah pertama apa yang kamu lakukan untuk menyelidikinya?
Jika batch job kamu terlambat 3 jam dari jadwal, komponen mana yang kamu cek terlebih dahulu?
Kamu mendapati duplicate record muncul di data warehouse. Bagaimana kamu men-troubleshoot sumber duplikasi?
Jika data real-time dari Kafka mengalami delay, apa langkah investigasi utamamu?
Bagaimana kamu menentukan apakah pipeline harus berjalan sebagai batch, streaming, atau hybrid?
Jika tabel fact kamu terus membesar hingga mengganggu performa query, strategi optimasi apa yang kamu lakukan?
Bagaimana kamu memilih metode partisi untuk tabel berukuran tera-byte?
Log ingestion sering gagal karena schema berubah tiba-tiba. Bagaimana kamu mendesain mekanisme schema evolution?
Jika data late-arrival muncul pada data streaming, bagaimana kamu menanganinya?
Bagaimana kamu merancang sistem data lineage untuk memudahkan auditing?
Jika salah satu node Hadoop mati saat proses sedang berjalan, apa yang kamu harapkan terjadi?
Bagaimana kamu memastikan data tetap konsisten di cluster dengan banyak node?
Jika sebuah job Spark memakan waktu lebih lama dari biasanya, komponen apa yang kamu cek?
Bagaimana kamu menentukan jumlah executor dan memory untuk Spark job?
Jika join pada Spark menyebabkan data skew, bagaimana kamu memperbaikinya?
Kamu diminta mendesain pipeline transaksi bank real-time. Komponen apa yang kamu pilih dan mengapa?
Bagaimana kamu mendesain arsitektur Data Lake agar tetap terorganisir meski data sangat beragam?
Jika kamu perlu memindahkan data dari on-prem ke cloud tanpa downtime, strategi apa yang kamu pilih?
Bagaimana kamu mendeteksi data drift pada data yang masuk ke data lake?
Jika sistem kamu menghasilkan event duplication, bagaimana kamu menjamin exactly-once processing?
Bagaimana kamu melakukan versioning pada data large-scale?
Jika performance query menurun akibat table scan besar, optimasi apa yang kamu lakukan?
Kamu menemukan anomali data di raw zone. Bagaimana kamu menentukan apakah data itu harus diperbaiki atau di-flag?
Jika data team lain sering mengakses tabel yang sama, bagaimana kamu memastikan tidak terjadi deadlock?
Bagaimana kamu mendesain dataset agar mudah di-query oleh BI Analyst?
Jika kamu perlu memilih antara Parquet, Avro, dan JSON, faktor apa yang kamu pertimbangkan?
Bagaimana kamu mengelola file kecil yang terlalu banyak pada HDFS?
Jika tabel dimensi sering berubah, bagaimana kamu menangani SCD (Slowly Changing Dimension)?
Bagaimana kamu mendesain ETL yang tetap berjalan meskipun ada satu source yang bermasalah?
Jika API untuk ingestion lambat, bagaimana kamu melakukan backpressure handling?
Bagaimana kamu mengatur orchestrasi pipeline agar dependensi antar job tetap aman?
Jika kamu diberi dataset tanpa dokumentasi, bagaimana kamu melakukan profiling awal?
Bagaimana kamu menentukan apakah perlu re-partition pada Spark?
Jika storage cost membengkak, apa strategi yang kamu sarankan ke perusahaan?
Bagaimana kamu mengonversi pipeline manual menjadi pipeline otomatis?
Jika kamu harus memvalidasi 10 juta baris data setiap hari, teknik validasi apa yang kamu pakai?
Bagaimana kamu mendesain alerting system untuk pipeline data?
Jika tabel tidak sinkron antara development dan production, bagaimana kamu mengatasinya?
Bagaimana kamu menentukan granularity terbaik untuk tabel fact?
Jika database OLTP menjadi bottleneck untuk ingestion, bagaimana kamu mengurangi bebannya?
Bagaimana kamu mendesain skema BigQuery atau Redshift agar hemat biaya?
Jika ingestion ke data lake tidak teratur, bagaimana kamu memastikan watermark konsisten?
Bagaimana kamu mengatasi file corrupt pada HDFS?
Jika cluster kamu mengalami hotspotting, apa penyebab dan solusinya?
Bagaimana kamu menangani perubahan schema di Kafka tanpa memutus consumer?
Jika kamu harus menghitung ulang seluruh warehouse, bagaimana kamu menghindari heavy recomputation?
Bagaimana kamu melakukan incremental load yang aman?
Jika kode ETL terlalu kompleks, bagaimana kamu melakukan refactoring?
Bagaimana kamu menyusun folder structure pada data lake?
Jika scheduler berhenti bekerja, bagaimana pipeline tetap bisa berjalan manual?
Bagaimana kamu melakukan secure data masking untuk data sensitif?
Jika update data sering dilakukan oleh banyak tim, bagaimana kamu mencegah race condition?
Bagaimana kamu membuat sistem audit log untuk seluruh pipeline?
Jika transformasi data memakan resource terlalu besar, bagaimana optimasinya?
Bagaimana kamu mendesain multi-region data pipeline?
Jika konsistensi lebih penting daripada availability, sistem apa yang kamu pilih?
Bagaimana kamu menangani batch job yang timeout saat memproses file besar?
Jika suatu job bergantung pada API eksternal, bagaimana kamu merancang fallback mechanism?
Bagaimana kamu mendeteksi perubahan struktur tabel source tanpa notifikasi?
Jika tabel tiba-tiba membengkak, bagaimana kamu melacak sumber duplikasinya?
Bagaimana kamu mendesain metadata management yang rapi?
Jika perusahaan ingin pindah dari monolithic ETL ke microservices, apa dampaknya?
Bagaimana kamu mengatur retention policy untuk cold data?
Jika suatu pipeline berubah behavior tanpa kode berubah, apa yang kamu curigai?
Bagaimana kamu melakukan stress test untuk pipeline data?
Jika streaming job tumpang tindih dengan batch job, bagaimana kamu mengatur prioritas resource?
Bagaimana kamu menangani schema mismatch pada file di data lake?
Jika partisi terlalu banyak, bagaimana kamu menggabungkannya tanpa kehilangan data?
Bagaimana kamu memutuskan kapan harus menggunakan materialized view?
Jika cluster penuh, apa langkah mitigasi cepat?
Bagaimana kamu memilih format kompresi untuk warehouse?
Jika raw data tidak dapat diubah, bagaimana kamu memperbaiki kualitas data di level processing?
Bagaimana kamu mengatasi data integrity ketika file datang tidak berurutan?
Jika business logic berubah, bagaimana kamu meng-update ETL tanpa mempengaruhi data historis?
Bagaimana kamu menghindari duplicate aggregation saat ETL rerun?
Jika load harian menjadi load per jam, apa perubahan arsitektur yang kamu lakukan?
Bagaimana kamu melakukan dependency management antar pipeline?
Jika data warehouse lambat saat peak time, strategi apa yang kamu pilih?
Bagaimana kamu mengelola encryption-at-rest dan encryption-in-transit pada pipeline?
Jika data conversion sering gagal karena type mismatch, bagaimana kamu menanganinya?
Bagaimana kamu mendesain CDC (Change Data Capture) pipeline yang reliabel?
Jika node executor sering mati, bagaimana kamu memastikan job tidak gagal total?
Bagaimana kamu mendesain rollback mechanism untuk data processing?
Jika job harus dipindah dari Hadoop ke Spark, bagaimana proses migrasinya?
Bagaimana kamu mencegah tabel fact menjadi terlalu denormalized?
Jika kamu harus memilih antara ETL atau ELT, apa faktor penentunya?
Bagaimana kamu membuat monitoring harian untuk memastikan tidak ada data hilang?
Jika pipeline bergantung pada banyak API yang tidak stabil, bagaimana kamu mendesain retry logic?
Bagaimana kamu memutuskan jumlah cluster yang optimal di cloud?
Jika tiba-tiba terjadi lonjakan data besar (data spike), apa strategi perlindungan pipeline?
Bagaimana kamu melakukan backfilling tanpa mengganggu job reguler?
Jika perusahaan ingin near-real-time analytics, arsitektur apa yang kamu usulkan?
Model klasifikasi kamu memiliki akurasi 95% tetapi recall kelas minoritas hanya 20%. Bagaimana kamu memperbaikinya?
Jika model menunjukkan overfitting, bagaimana kamu memutuskan apakah perlu regularisasi atau menambah data?
Dataset training jauh lebih bersih dibanding data real-time. Bagaimana kamu mencegah penurunan performa setelah deployment?
Jika model inference lambat, bagaimana kamu memilih antara quantization, pruning, atau distillation?
Bagaimana kamu memutuskan threshold terbaik untuk model binary classification?
Modelmu menghasilkan output probabilitas yang tidak terkalibrasi. Teknik apa yang kamu gunakan untuk memperbaikinya?
Jika training loss turun tetapi validation loss naik, langkah investigasi apa yang kamu ambil?
Bagaimana kamu merancang pipeline automated retraining untuk model produksi?
Model kamu sering salah pada edge cases tertentu. Bagaimana kamu meningkatkan robustness?
Jika dataset sangat imbalance, kapan kamu memilih SMOTE daripada threshold tuning?
Model mengalami data leakage tanpa disadari. Bagaimana kamu mendeteksinya?
Jika kamu menemukan bahwa satu fitur membuat model sangat bias, apa strategi mitigasinya?
Bagaimana kamu menentukan apakah harus menggunakan model linear atau nonlinear?
Jika multi-class classification memiliki kelas jarang, bagaimana kamu mengatasi masalah tersebut?
Bagaimana kamu melakukan hyperparameter tuning untuk model yang membutuhkan waktu training lama?
Model cenderung memberikan hasil yang overconfident. Bagaimana kamu menurunkan overconfidence?
Jika dua model performanya mirip, bagaimana kamu memilih model yang lebih siap untuk produksi?
Bagaimana kamu menggunakan SHAP atau LIME untuk menjelaskan prediksi model?
Model kamu bekerja baik pada training tapi buruk pada data baru. Apakah ini masalah domain shift?
Jika dataset memiliki missing value yang tidak random, teknik imputasi apa yang kamu pilih?
Bagaimana kamu merancang struktur fitur yang tetap stabil meski data berubah setiap hari?
Model rekomendasi kamu memberikan rekomendasi terlalu generik. Bagaimana kamu membuatnya lebih personal?
Bagaimana kamu menentukan kapan perlu melakukan feature selection vs feature extraction?
Jika outlier sangat memengaruhi model, bagaimana kamu memutuskan menghapus atau mentransformasinya?
Bagaimana kamu memastikan model tidak bias terhadap kelompok tertentu?
Jika kamu harus memilih antara model interpretable vs akurat, bagaimana kamu memutuskan?
Model training sangat lambat. Bagaimana kamu memutuskan apakah masalahnya CPU, GPU, I/O atau batch size?
Dataset sangat besar tidak muat di RAM. Bagaimana kamu melakukan training secara efisien?
Jika business owner meminta model mudah dijelaskan, metode ML apa yang kamu pilih?
Bagaimana kamu menghindari fitur yang bersifat data leakage?
Jika model berbasis tree overfitting, teknik apa yang kamu gunakan untuk mengontrolnya?
Bagaimana kamu menangani categorical variable dengan 10.000 kategori?
Model NLP kamu salah mengartikan konteks karena dataset noisy. Bagaimana kamu membersihkannya?
Bagaimana kamu menentukan embedding dimension yang optimal untuk model deep learning?
Jika model CNN sulit mengenali objek kecil, bagaimana kamu memperbaikinya?
Bagaimana kamu memutuskan apakah perlu augmentasi data pada dataset gambar?
Jika inference harus berjalan di device kecil, bagaimana kamu mengoptimalkan model?
Model reinforcement learning kamu tidak stabil saat training. Bagaimana kamu memperbaikinya?
Bagaimana kamu menentukan gamma dan learning rate pada model RL?
Jika reward function buruk, bagaimana kamu mendesain ulang reward?
Model time-series kamu tidak bisa menangkap pola musiman. Apa solusi terbaiknya?
Bagaimana kamu memilih antara ARIMA, Prophet, atau LSTM?
Jika dataset time-series mengalami perubahan pola tiba-tiba, bagaimana kamu mendeteksi concept drift?
Model kamu memerlukan deteksi anomali, apa pendekatan yang kamu pilih?
Jika model menghasilkan banyak false positive, bagaimana kamu mengurangi jumlahnya?
Bagaimana kamu melakukan cross-validation pada dataset time-series?
Jika model memprediksi nilai yang mustahil, apa langkah sanity check yang kamu lakukan?
Bagaimana kamu menentukan jumlah cluster optimal pada data clustering?
Jika PCA tidak bekerja baik karena hubungan nonlinear, teknik apa yang kamu pakai?
Bagaimana kamu mengatasi curse of dimensionality?
Jika model klasifikasi tidak stabil antar run, bagaimana kamu meningkatkan konsistensinya?
Bagaimana kamu menentukan apakah data harus di-scale atau tidak sebelum training?
Jika dataset teks banyak mengandung typo, teknik preprocessing apa yang kamu gunakan?
Bagaimana kamu memastikan bahwa pipeline fitur sama antara training dan inference?
Jika training berjalan di distributed cluster, bagaimana kamu menghindari deadlock?
Bagaimana kamu memilih antara batch vs online learning?
Jika dataset memiliki banyak noise, kapan kamu menggunakan robust model?
Bagaimana kamu mengukur fairness model?
Model regression memiliki error besar pada outlier. Bagaimana kamu menanganinya?
Jika model tidak generalize pada domain baru, bagaimana kamu melakukan domain adaptation?
Bagaimana kamu memilih loss function untuk regression dan classification?
Jika model multi-label classification salah prediksi pada kombinasi label, bagaimana kamu memperbaikinya?
Bagaimana kamu memilih arsitektur neural network berdasarkan tipe data?
Jika GPU memory selalu penuh, apa yang kamu lakukan?
Bagaimana kamu mengatasi exploding gradient?
Jika model gagal convergence, bagaimana kamu mengatasi vanishing gradient?
Bagaimana kamu menentukan batch size optimal?
Model forecasting error tinggi karena outlier, bagaimana kamu memperbaikinya?
Jika window size pada time-series tidak tepat, bagaimana kamu menemukannya?
Bagaimana kamu melakukan feature scaling pada data sparse?
Jika dataset imbalance ekstrem, mengapa accuracy bukan metrik yang tepat?
Bagaimana kamu memilih evaluation metric berdasarkan tujuan bisnis?
Model ensemble kamu terlalu berat untuk produksi. Bagaimana kamu menyederhanakannya?
Jika kamu melakukan stacking, bagaimana kamu memastikan base model tetap diverse?
Bagaimana kamu mendesain pipeline ML yang tahan failure?
Jika ingin membuat ML system low-latency, komponen apa yang harus diperhatikan?
Bagaimana kamu mendeteksi data poisoning attack?
Jika log inference tidak konsisten, bagaimana kamu melakukan observability?
Bagaimana kamu memilih antara CPU serving dan GPU serving?
Model kamu harus berjalan di edge device. Arsitektur mana yang kamu rekomendasikan?
Bagaimana kamu men-deploy model secara canary release?
Jika throughput inferensi rendah, bagaimana kamu meningkatkan parallelism?
Bagaimana kamu memastikan golden dataset untuk regression testing model?
Jika model mengalami feedback loop bias, bagaimana kamu memutus rantai bias?
Bagaimana kamu memonitor drift secara real-time?
Jika model tidak mau update karena data baru berbeda, bagaimana kamu menangani catastrophic forgetting?
Bagaimana kamu membuat model continual learning?
Jika pipeline ML gagal di tahap feature generation, apa yang kamu cek?
Bagaimana kamu menyatukan logic rule-based dan ML dalam satu sistem?
Jika terjadi perubahan besar pada input distribution, bagaimana kamu melakukan redeployment?
Bagaimana kamu memilih antara MLOps tool seperti MLflow, Kubeflow, atau SageMaker?
Jika storage besar dipakai menyimpan model versi lama, bagaimana kamu melakukan model pruning?
Bagaimana kamu membuat model robust terhadap adversarial attack?
Jika model harus explainable untuk auditor, teknik apa yang kamu gunakan?
Bagaimana kamu mendesain arsitektur ML end-to-end dari data ingestion sampai monitoring?
Model mengalami inference spike sesaat yang membahayakan sistem. Bagaimana kamu menstabilkannya?
